{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUV610jQdvEe"
      },
      "source": [
        "Downaloadig and extracting mscoco dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i3X-_3CVcJy"
      },
      "source": [
        "#Steps to get the training and validation images from coco\n",
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!unzip -q train2014.zip\n",
        "\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FixkHCEKCb5r"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0cApSkcYglT"
      },
      "source": [
        "Removing zipped filed to save disk space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJsSMqWrBwMq"
      },
      "source": [
        "os.remove('/content/train2014.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k655zLAhBRLx"
      },
      "source": [
        "\n",
        "!wget http://images.cocodataset.org/zips/val2014.zip\n",
        "!unzip -q val2014.zip\n",
        "!unzip -q annotations_trainval2014.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm1pyheNBzPl"
      },
      "source": [
        "os.remove('/content/val2014.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMgdPn9nBrKt"
      },
      "source": [
        "#Download coco api\n",
        "! pip install 2to3\n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi\n",
        "!2to3 . -w\n",
        "%cd PythonAPI\n",
        "!python3 setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjcrkQ-zYqZ5"
      },
      "source": [
        "Importing COCO API "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PArIbz4AwuzO"
      },
      "source": [
        "from pycocotools import  _mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trhgcZgxVml4"
      },
      "source": [
        "\n",
        "# Importing Data From COCO\n",
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "\n",
        "from pycocotools import coco, cocoeval, _mask\n",
        "from pycocotools import mask as maskUtils \n",
        "import array\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import os\n",
        "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0AaVoN9bMSM"
      },
      "source": [
        "Setting TensorFlow version and checking Avaiable GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n78zTpbs5JrG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "0921756d-a195-4c92-d051-c9b15bba2123"
      },
      "source": [
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "/device:GPU:0\n",
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka3_cKTK5EpN"
      },
      "source": [
        "import sys\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "\n",
        "seed = 2019\n",
        "\n",
        "random.seed = seed\n",
        "np.random.seed = seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhy752M0hb-r"
      },
      "source": [
        "Annoations for Person Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcFlXnqwVr3E"
      },
      "source": [
        "CATEGORY_NAMES=['person']\n",
        "\n",
        "ANNOTATION_FILE_VAL = '/content/annotations/instances_val2014.json'\n",
        "ANNOTATION_FILE_TRAIN = '/content/annotations/instances_train2014.json'\n",
        "\n",
        "\n",
        "coco_train = coco.COCO(ANNOTATION_FILE_TRAIN)\n",
        "catIds_train = coco_train.getCatIds(catNms=CATEGORY_NAMES);\n",
        "imgIds_train = coco_train.getImgIds(catIds=catIds_train);\n",
        "imgDict_train = coco_train.loadImgs(imgIds_train)\n",
        "len(imgIds_train) , len(catIds_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "coco_val = coco.COCO(ANNOTATION_FILE_VAL)\n",
        "catIds_val = coco_val.getCatIds(catNms=CATEGORY_NAMES);\n",
        "imgIds_val = coco_val.getImgIds(catIds=catIds_val);\n",
        "imgDict_val = coco_val.loadImgs(imgIds_val)\n",
        "len(imgIds_val) , len(catIds_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI2TdYkvVxpO"
      },
      "source": [
        "\n",
        "from random import shuffle\n",
        "\n",
        "\n",
        "shuffle(imgIds_train)\n",
        "shuffle(imgIds_val)\n",
        "\n",
        "imgIds_train = imgIds_train[0:6000]  # 6000 Training \n",
        "imgIds_val = imgIds_val[0:600]       # 600 Validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQaN07IBcCLt"
      },
      "source": [
        "Generating names for Training and Validation files with 12 digits at the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6_ZpxSV1Q3"
      },
      "source": [
        "train_images_person = [\"COCO_train2014_{0:012d}.jpg\".format(ids) for ids in imgIds_train]\n",
        "val_images_person = [\"COCO_val2014_{0:012d}.jpg\".format(ids) for ids in imgIds_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gngs_denV4E-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c42ccc9-7017-492a-99cf-a55e89ed3724"
      },
      "source": [
        "print(len(train_images_person) , len(val_images_person))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVlNq0MSWCM-"
      },
      "source": [
        "\n",
        "train_images_person = [\"COCO_train2014_{0:012d}.jpg\".format(ids) for ids in imgIds_train]\n",
        "print(train_images_person)\n",
        "del_img_train = set(os.listdir(\"/content/train2014\")) - set(train_images_person)\n",
        "for file_name in del_img_train:\n",
        "  file_name = \"/content/train2014/\" + file_name\n",
        "  if os.path.exists(file_name):\n",
        "    os.remove(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVVNLC_vWD7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3570b99-ee58-486e-bebb-8abc1d50956b"
      },
      "source": [
        "print(len(os.listdir(\"/content/train2014\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbjMSROFWGRp"
      },
      "source": [
        "val_images_person = [\"COCO_val2014_{0:012d}.jpg\".format(ids) for ids in imgIds_val]\n",
        "print(val_images_person)\n",
        "del_img_val = set(os.listdir(\"/content/val2014\")) - set(val_images_person)\n",
        "for file_name in del_img_val:\n",
        "  file_name = \"/content/val2014/\" + file_name\n",
        "  if os.path.exists(file_name):\n",
        "    os.remove(file_name)\n",
        "\n",
        "len(os.listdir(\"/content/val2014\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRSRD3OeWIbr"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqmGkY-NWKhV"
      },
      "source": [
        "!mkdir mask_train_2014"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj_1ET-6eOnF"
      },
      "source": [
        "creating mask for training image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVeIeiIlWMRA"
      },
      "source": [
        "count = 0 \n",
        "#creating mask for the training image and saving them\n",
        "for ID in imgIds_train:\n",
        "\n",
        "  file_path = \"/content/mask_train_2014/COCO_train2014_{0:012d}.jpg\".format(ID)\n",
        "  \n",
        "  sampleImgIds = coco_train.getImgIds(imgIds = [ID])\n",
        "  sampleImgDict = coco_train.loadImgs(sampleImgIds[np.random.randint(0,len(sampleImgIds))])[0]\n",
        "\n",
        "  annIds = coco_train.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_train, iscrowd=0)\n",
        "  anns = coco_train.loadAnns(annIds)\n",
        "\n",
        "\n",
        "  mask = coco_train.annToMask(anns[0])\n",
        "  for i in range(len(anns)):\n",
        "      mask = mask | coco_train.annToMask(anns[i])\n",
        "  \n",
        "  mask = Image.fromarray(mask * 255 , mode = \"L\")\n",
        "  mask.save(file_path)\n",
        "  count = count + 1\n",
        "  print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8vYFvw_WPO9"
      },
      "source": [
        "!mkdir mask_val_2014"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G27x8tqeVOV"
      },
      "source": [
        "creating mask for validation image "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y68wQ2QZWRez"
      },
      "source": [
        "count = 0 \n",
        "\n",
        "for ID in imgIds_val:\n",
        "\n",
        "  file_path = \"/content/mask_val_2014/COCO_val2014_{0:012d}.jpg\".format(ID)\n",
        "  \n",
        "  sampleImgIds = coco_val.getImgIds(imgIds = [ID])\n",
        "  sampleImgDict = coco_val.loadImgs(sampleImgIds[np.random.randint(0,len(sampleImgIds))])[0]\n",
        "\n",
        "  annIds = coco_val.getAnnIds(imgIds=sampleImgDict['id'], catIds=catIds_val, iscrowd=0)\n",
        "  anns = coco_val.loadAnns(annIds)\n",
        "\n",
        "\n",
        "  mask = coco_val.annToMask(anns[0])\n",
        "  for i in range(len(anns)):\n",
        "      mask = mask | coco_val.annToMask(anns[i])\n",
        "  \n",
        "  mask = Image.fromarray(mask * 255 , mode = \"L\")\n",
        "  mask.save(file_path)\n",
        "  \n",
        "  count = count + 1\n",
        "  print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Vt-8yYWTwK"
      },
      "source": [
        "\n",
        "!rm -rf annotations/\n",
        "!rm -rf train2014.zip\n",
        "!rm -rf val2014.zip\n",
        "!rm -rf annotations_trainval2014.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iiyh4TPxgYiG"
      },
      "source": [
        " Agumenation with same seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhZ2SLqrWYUH"
      },
      "source": [
        "class DataGen(tf.keras.utils.Sequence):\n",
        "  \n",
        "  def __init__(self , path_input , path_mask , batch_size = 5 , image_size = 512):\n",
        "    \n",
        "    self.ids = os.listdir(path_input)\n",
        "    self.path_input = path_input\n",
        "    self.path_mask = path_mask\n",
        "    self.batch_size = batch_size\n",
        "    self.image_size = image_size\n",
        "    self.on_epoch_end()\n",
        "  \n",
        "  def __load__(self , id_name):\n",
        "    \n",
        "    image_path = os.path.join(self.path_input , id_name)\n",
        "    mask_path = os.path.join(self.path_mask , id_name) \n",
        "    \n",
        "    image = cv2.imread(image_path , 1) # 1 specifies RGB format\n",
        "    image = cv2.resize(image , (self.image_size , self.image_size)) # resizing before inserting to the network\n",
        "    \n",
        "    mask = cv2.imread(mask_path , -1)\n",
        "    mask = cv2.resize(mask , (self.image_size , self.image_size))\n",
        "    mask = mask.reshape((self.image_size , self.image_size , 1))\n",
        "      \n",
        "    #normalize image\n",
        "    image = image / 255.0\n",
        "    mask = mask / 255.0\n",
        "    \n",
        "    return image , mask\n",
        "  \n",
        "  def __getitem__(self , index):\n",
        "    \n",
        "    if (index + 1)*self.batch_size > len(self.ids):\n",
        "      self.batch_size = len(self.ids) - index * self.batch_size\n",
        "        \n",
        "    file_batch = self.ids[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    \n",
        "    images = []\n",
        "    masks = []\n",
        "    \n",
        "    for id_name in file_batch : \n",
        "      \n",
        "      _img , _mask = self.__load__(id_name)\n",
        "      images.append(_img)\n",
        "      masks.append(_mask)\n",
        "    \n",
        "    \n",
        "    images = np.array(images)\n",
        "    masks = np.array(masks)\n",
        "    \n",
        "    \n",
        "    return images , masks\n",
        "  \n",
        "  \n",
        "  def on_epoch_end(self):\n",
        "    pass\n",
        "  \n",
        "  \n",
        "  def __len__(self):\n",
        "    \n",
        "\n",
        "    return int(np.ceil(len(self.ids) / float(self.batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziPStdENeyeH"
      },
      "source": [
        "Contraction Part of UNET "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MT0KdlMWdj_"
      },
      "source": [
        "def contraction_block(\n",
        "    input_tensor,\n",
        "    no_filters,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=\"he_normal\",\n",
        "    max_pool_window=(2, 2),\n",
        "    max_pool_stride=(2, 2)\n",
        "):\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(input_tensor)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    # conv for skip connection\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    pool = MaxPooling2D(pool_size=max_pool_window, strides=max_pool_stride)(conv)\n",
        "\n",
        "    return conv, pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHucPx4ie4Pq"
      },
      "source": [
        "Bottle Neck Layer of UNET "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZeNKwMOWhyn"
      },
      "source": [
        "def bottle_neck(\n",
        "    input_tensor,\n",
        "    no_filters,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=\"he_normal\"\n",
        "):\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(input_tensor)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    return conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_soQmSxfAtv"
      },
      "source": [
        "Expansion Block of UNET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgFjN3CqWlAV"
      },
      "source": [
        "def expansion_block(    \n",
        "    input_tensor,\n",
        "    no_filters,\n",
        "    skip_connection, \n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    upsampling_factor = (2,2),\n",
        "    max_pool_window = (2,2),\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=\"he_normal\"):\n",
        "    \n",
        "    \n",
        "    conv = Conv2D(\n",
        "        filters = no_filters,\n",
        "        kernel_size= max_pool_window,\n",
        "        strides = strides,\n",
        "        activation = None,\n",
        "        padding = padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(UpSampling2D(size = upsampling_factor)(input_tensor))\n",
        "    \n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)     \n",
        "\n",
        "    \n",
        "    conv = concatenate( [skip_connection , conv]  , axis = -1)\n",
        "    \n",
        "    \n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = Conv2D(\n",
        "        filters=no_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        activation=None,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "\n",
        "    conv = BatchNormalization(scale=True)(conv)\n",
        "\n",
        "    conv = Activation(\"relu\")(conv)\n",
        "    \n",
        "    return conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wpDrF-ufJyi"
      },
      "source": [
        "Final OUTPUT Layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qysqf5YWpGr"
      },
      "source": [
        "def output_block(input_tensor,\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=\"he_normal\"\n",
        "):\n",
        "    \n",
        "    conv = Conv2D(\n",
        "        filters=2,\n",
        "        kernel_size=(3,3),\n",
        "        strides=(1,1),\n",
        "        activation=\"relu\",\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(input_tensor)\n",
        "    \n",
        "    \n",
        "    conv = Conv2D(\n",
        "        filters=1,\n",
        "        kernel_size=(1,1),\n",
        "        strides=(1,1),\n",
        "        activation=\"sigmoid\",\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer\n",
        "    )(conv)\n",
        "    \n",
        "    \n",
        "    return conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDvthDnlWsCb"
      },
      "source": [
        "def UNet(input_shape = (512,512,3)):\n",
        "    \n",
        "    filter_size = [64,128,256,512,1024]\n",
        "    \n",
        "    inputs = Input(shape = input_shape)\n",
        "    \n",
        "    d1 , p1 = contraction_block(input_tensor= inputs,\n",
        "                         no_filters=filter_size[0],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\",\n",
        "                         max_pool_window=(2,2),\n",
        "                         max_pool_stride=(2,2))\n",
        "    \n",
        "    \n",
        "    d2 , p2 = contraction_block(input_tensor= p1,\n",
        "                         no_filters=filter_size[1],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\",\n",
        "                         max_pool_window=(2,2),\n",
        "                         max_pool_stride=(2,2))\n",
        "    \n",
        "    \n",
        "    \n",
        "    d3 , p3 = contraction_block(input_tensor= p2,\n",
        "                         no_filters=filter_size[2],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\",\n",
        "                         max_pool_window=(2,2),\n",
        "                         max_pool_stride=(2,2))\n",
        "    \n",
        "    \n",
        "    \n",
        "    d4 , p4 = contraction_block(input_tensor= p3,\n",
        "                         no_filters=filter_size[3],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\",\n",
        "                         max_pool_window=(2,2),\n",
        "                         max_pool_stride=(2,2))\n",
        "    \n",
        "    \n",
        "    b = bottle_neck(input_tensor= p4,\n",
        "                         no_filters=filter_size[4],\n",
        "                         kernel_size = (3,3),\n",
        "                         strides=(1,1),\n",
        "                         padding=\"same\",\n",
        "                         kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    u4 = expansion_block(input_tensor = b,\n",
        "                  no_filters = filter_size[3],\n",
        "                  skip_connection = d4,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1, 1),\n",
        "                  upsampling_factor = (2,2),\n",
        "                  max_pool_window = (2,2),\n",
        "                  padding=\"same\",\n",
        "                  kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    u3 = expansion_block(input_tensor = u4,\n",
        "                  no_filters = filter_size[2],\n",
        "                  skip_connection = d3,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1, 1),\n",
        "                  upsampling_factor = (2,2),\n",
        "                  max_pool_window = (2,2),\n",
        "                  padding=\"same\",\n",
        "                  kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    \n",
        "    u2 = expansion_block(input_tensor = u3,\n",
        "                  no_filters = filter_size[1],\n",
        "                  skip_connection = d2,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1, 1),\n",
        "                  upsampling_factor = (2,2),\n",
        "                  max_pool_window = (2,2),\n",
        "                  padding=\"same\",\n",
        "                  kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    \n",
        "    u1 = expansion_block(input_tensor = u2,\n",
        "                  no_filters = filter_size[0],\n",
        "                  skip_connection = d1,\n",
        "                  kernel_size=(3, 3),\n",
        "                  strides=(1, 1),\n",
        "                  upsampling_factor = (2,2),\n",
        "                  max_pool_window = (2,2),\n",
        "                  padding=\"same\",\n",
        "                  kernel_initializer=\"he_normal\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    output = output_block(input_tensor=u1 , \n",
        "                         padding = \"same\",\n",
        "                         kernel_initializer= \"he_normal\")\n",
        "    \n",
        "    model = keras.models.Model(inputs = inputs , outputs = output)\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "095Z4Uj_fUy1"
      },
      "source": [
        "MIOU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2m4QMT7q_MP"
      },
      "source": [
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4VnqV5E89tG"
      },
      "source": [
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G_11QnK9X_l"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXS5qzhYW1vp"
      },
      "source": [
        "\n",
        "model = UNet(input_shape = (512,512,3))\n",
        "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy']) #Accuracy /MIOU\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_QS6aFBW4nA"
      },
      "source": [
        "\n",
        "image_size = 512 \n",
        "epochs = 50\n",
        "batch_size = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axLccha-wpXH"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8PZUh6CW8ZP"
      },
      "source": [
        "\n",
        "train_gen = DataGen(path_input = \"/content/train2014\" , path_mask = \"/content/mask_train_2014/\" , batch_size = batch_size , image_size = image_size)\n",
        "val_gen = DataGen(path_input =  \"/content/val2014\", path_mask =  \"/content/mask_val_2014\", batch_size = batch_size , image_size = image_size)\n",
        "\n",
        "\n",
        "train_steps =  len(os.listdir( \"/content/train2014\"))/batch_size\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.01, verbose=1),\n",
        "    ModelCheckpoint('unetMay11NewV1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]\n",
        "\n",
        "result = model.fit_generator(train_gen , validation_data = val_gen , steps_per_epoch = train_steps , epochs=epochs,callbacks= callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVln8KKjPPwI"
      },
      "source": [
        "from keras.callbacks import History \n",
        "history = History()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJnmcx94PoGM"
      },
      "source": [
        "print(history.History)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJsOuXUzouZO"
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.plot(result.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(result.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot( np.argmin(result.history[\"val_loss\"]), np.min(result.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"log_loss\")\n",
        "plt.legend();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gjo5NFEPW--T"
      },
      "source": [
        "print(\"\\n      Ground Truth            Predicted Value\")\n",
        "for i in range(60, 70, 1):\n",
        "  x, y = val_gen.__getitem__(i)\n",
        "  result = model.predict(x)\n",
        "\n",
        "  result = result > 0.5\n",
        "\n",
        "\n",
        "\n",
        "  fig = plt.figure()\n",
        "  fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "  ax = fig.add_subplot(1, 2, 1)\n",
        "  ax.imshow(np.reshape(y[0]*255, (image_size, image_size)), cmap=\"gray\")\n",
        "\n",
        "  ax = fig.add_subplot(1, 2, 2)\n",
        "  ax.imshow(np.reshape(result[0]*255, (image_size, image_size)), cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3x0SIbEn1hZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}